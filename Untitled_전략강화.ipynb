{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1lPjUZncfwrNVXDkOqp_tjlFE8I6F8Bo7",
      "authorship_tag": "ABX9TyPGKfjjP0xP7ZRoXyfgq2s7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/Dacon_cacer/blob/main/Untitled_%EC%A0%84%EB%9E%B5%EA%B0%95%ED%99%94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67Tx9btmkX7m",
        "outputId": "d2edcc59-5890-404f-901b-962adf9c9d7f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o \"/content/drive/MyDrive/open_1.zip\" -d \"/content/open_1\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuaLWGZLg1cb",
        "outputId": "e45acb1c-4c25-436a-95c6-24c5f055a9bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/open_1.zip\n",
            "  inflating: /content/open_1/sample_submission.csv  \n",
            "  inflating: /content/open_1/test.csv  \n",
            "  inflating: /content/open_1/train.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_path(filename):\n",
        "    return \"/content/open_1/\" + filename\n"
      ],
      "metadata": {
        "id": "X47pnDLzhGy6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SMOTE 설치\n",
        "!pip install -U imbalanced-learn\n",
        "!pip install lightgbm optuna\n",
        "!pip install -q lightgbm catboost xgboost\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1_zgPGeiKVN",
        "outputId": "a15c9e6a-723d-425e-a1b2-e00fe8153df6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.2 colorlog-6.9.0 optuna-4.4.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade lightgbm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETzKBXBvKA3a",
        "outputId": "f9365f69-7081-4b78-9d58-bc982a29c772"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Collecting lightgbm\n",
            "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\n",
            "Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightgbm\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 4.5.0\n",
            "    Uninstalling lightgbm-4.5.0:\n",
            "      Successfully uninstalled lightgbm-4.5.0\n",
            "Successfully installed lightgbm-4.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "print(lgb.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbtYwcmfi0lI",
        "outputId": "00c1c80f-1bbd-49fa-e14f-0da209d644f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전략 A: Soft Voting Ensemble\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# ✅ 데이터 경로\n",
        "def get_path(filename):\n",
        "    return \"/content/open_1/\" + filename\n",
        "\n",
        "# ✅ 데이터 로딩\n",
        "train = pd.read_csv(get_path(\"train.csv\"))\n",
        "test = pd.read_csv(get_path(\"test.csv\"))\n",
        "submission = pd.read_csv(get_path(\"sample_submission.csv\"))\n",
        "\n",
        "y = train[\"Cancer\"]\n",
        "X = train.drop(columns=[\"ID\", \"Cancer\"])\n",
        "X_test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "# ✅ 전처리\n",
        "def preprocess(df, encoders=None):\n",
        "    df = df.copy()\n",
        "    encoders = encoders or {}\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == \"object\":\n",
        "            df[col] = df[col].astype(str)\n",
        "            if col not in encoders:\n",
        "                encoders[col] = LabelEncoder().fit(df[col])\n",
        "            df[col] = encoders[col].transform(df[col])\n",
        "        else:\n",
        "            df[col] = SimpleImputer(strategy=\"mean\").fit_transform(df[[col]])\n",
        "    return df, encoders\n",
        "\n",
        "X, encoders = preprocess(X)\n",
        "X_test, _ = preprocess(X_test, encoders)\n",
        "\n",
        "# ✅ 모델 정의\n",
        "model_lgbm = LGBMClassifier(learning_rate=0.05, max_depth=6, num_leaves=31, random_state=42)\n",
        "model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "model_cat = CatBoostClassifier(verbose=0, random_state=42)\n",
        "\n",
        "ensemble_model = VotingClassifier(\n",
        "    estimators=[(\"lgbm\", model_lgbm), (\"xgb\", model_xgb), (\"cat\", model_cat)],\n",
        "    voting=\"soft\"\n",
        ")\n",
        "\n",
        "# ✅ OOF 기반 Threshold 최적화\n",
        "oof_preds = cross_val_predict(ensemble_model, X, y, cv=5, method=\"predict_proba\")[:, 1]\n",
        "thresholds = np.arange(0.1, 0.9, 0.01)\n",
        "f1s = [f1_score(y, oof_preds > t) for t in thresholds]\n",
        "best_thresh = thresholds[np.argmax(f1s)]\n",
        "print(f\"Best Threshold: {best_thresh}, Best F1: {max(f1s):.5f}\")\n",
        "\n",
        "# ✅ 최종 학습 & 예측\n",
        "ensemble_model.fit(X, y)\n",
        "test_preds = ensemble_model.predict_proba(X_test)[:, 1]\n",
        "submission[\"Cancer\"] = (test_preds > best_thresh).astype(int)\n",
        "submission.to_csv(\"submission_voting_lgbm_xgb_cat.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVetqxST7PAR",
        "outputId": "a5a83bdd-8fdd-4972-d185-1a9b5751f3a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 8367, number of negative: 61360\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029821 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 69727, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119997 -> initscore=-1.992463\n",
            "[LightGBM] [Info] Start training from score -1.992463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:05:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 8367, number of negative: 61360\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020178 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1123\n",
            "[LightGBM] [Info] Number of data points in the train set: 69727, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119997 -> initscore=-1.992463\n",
            "[LightGBM] [Info] Start training from score -1.992463\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:06:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 8367, number of negative: 61360\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012899 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1123\n",
            "[LightGBM] [Info] Number of data points in the train set: 69727, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119997 -> initscore=-1.992463\n",
            "[LightGBM] [Info] Start training from score -1.992463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:06:54] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 8367, number of negative: 61360\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012356 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1123\n",
            "[LightGBM] [Info] Number of data points in the train set: 69727, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119997 -> initscore=-1.992463\n",
            "[LightGBM] [Info] Start training from score -1.992463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:07:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 8368, number of negative: 61360\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011677 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1122\n",
            "[LightGBM] [Info] Number of data points in the train set: 69728, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.120009 -> initscore=-1.992343\n",
            "[LightGBM] [Info] Start training from score -1.992343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:08:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold: 0.22999999999999995, Best F1: 0.48484\n",
            "[LightGBM] [Info] Number of positive: 10459, number of negative: 76700\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026090 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1123\n",
            "[LightGBM] [Info] Number of data points in the train set: 87159, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.119999 -> initscore=-1.992439\n",
            "[LightGBM] [Info] Start training from score -1.992439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [06:08:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔸 선택 시 다운로드 코드\n",
        "from google.colab import files\n",
        "files.download(\"submission_voting_lgbm_xgb_cat.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "pZBjmiey-NAz",
        "outputId": "e8e577a3-3b87-4dfc-cbfc-51d619182f2c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2afda186-02f7-495e-865b-a5294edb80a4\", \"submission_voting_lgbm_xgb_cat.csv\", 600662)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전략 B: StackingClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# ✅ 경로 함수\n",
        "def get_path(filename):\n",
        "    return \"/content/open_1/\" + filename\n",
        "\n",
        "# ✅ 데이터 로드\n",
        "train = pd.read_csv(get_path(\"train.csv\"))\n",
        "test = pd.read_csv(get_path(\"test.csv\"))\n",
        "submission = pd.read_csv(get_path(\"sample_submission.csv\"))\n",
        "\n",
        "y = train[\"Cancer\"]\n",
        "X = train.drop(columns=[\"ID\", \"Cancer\"])\n",
        "X_test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "# ✅ 전처리\n",
        "def preprocess(df, encoders=None):\n",
        "    df = df.copy()\n",
        "    encoders = encoders or {}\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == \"object\":\n",
        "            df[col] = df[col].astype(str)\n",
        "            if col not in encoders:\n",
        "                encoders[col] = LabelEncoder().fit(df[col])\n",
        "            df[col] = encoders[col].transform(df[col])\n",
        "        else:\n",
        "            df[col] = SimpleImputer(strategy=\"mean\").fit_transform(df[[col]])\n",
        "    return df, encoders\n",
        "\n",
        "X, encoders = preprocess(X)\n",
        "X_test, _ = preprocess(X_test, encoders)\n",
        "\n",
        "# ✅ 기본 모델 정의\n",
        "model_lgbm = LGBMClassifier(learning_rate=0.05, max_depth=6, num_leaves=31, random_state=42)\n",
        "model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "model_cat = CatBoostClassifier(verbose=0, random_state=42)\n",
        "\n",
        "# ✅ 스태킹 구성\n",
        "base_models = [\n",
        "    ('lgbm', model_lgbm),\n",
        "    ('xgb', model_xgb),\n",
        "    ('cat', model_cat)\n",
        "]\n",
        "meta_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=meta_model,\n",
        "    cv=5,\n",
        "    stack_method=\"predict_proba\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# ✅ OOF 기반 Threshold 최적화\n",
        "oof_preds = cross_val_predict(stack_model, X, y, method=\"predict_proba\", cv=5)[:, 1]\n",
        "thresholds = np.arange(0.1, 0.9, 0.01)\n",
        "f1s = [f1_score(y, oof_preds > t) for t in thresholds]\n",
        "best_thresh = thresholds[np.argmax(f1s)]\n",
        "print(f\"Best Threshold: {best_thresh:.2f}, Best F1: {max(f1s):.5f}\")\n",
        "\n",
        "# ✅ 전체 학습 및 예측\n",
        "stack_model.fit(X, y)\n",
        "test_preds = stack_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# ✅ 제출 저장\n",
        "submission[\"Cancer\"] = (test_preds > best_thresh).astype(int)\n",
        "submission.to_csv(\"submission_stacking.csv\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z67p7CT_p2-C",
        "outputId": "ceac415b-48ce-455a-dfcd-8954d5a78706"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold: 0.13, Best F1: 0.48592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔸 선택 시 다운로드 코드\n",
        "from google.colab import files\n",
        "files.download(\"submission_stacking.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "U1H-KAcap3FN",
        "outputId": "e18a1140-e746-4240-919f-c2f96097f876"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d5e43e65-01e0-4e96-95a7-5ae827766048\", \"submission_stacking.csv\", 600662)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전략 B-2: LGBMClassifier 메타 모델 기반 StackingClassifier 전체 코드\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# ✅ 경로 함수\n",
        "def get_path(filename):\n",
        "    return \"/content/open_1/\" + filename  # 환경에 맞게 경로 수정\n",
        "\n",
        "# ✅ 데이터 로딩\n",
        "train = pd.read_csv(get_path(\"train.csv\"))\n",
        "test = pd.read_csv(get_path(\"test.csv\"))\n",
        "submission = pd.read_csv(get_path(\"sample_submission.csv\"))\n",
        "\n",
        "y = train[\"Cancer\"]\n",
        "X = train.drop(columns=[\"ID\", \"Cancer\"])\n",
        "X_test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "# ✅ 전처리 (라벨 인코딩 + 결측치)\n",
        "def preprocess(df, encoders=None):\n",
        "    df = df.copy()\n",
        "    encoders = encoders or {}\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == \"object\":\n",
        "            df[col] = df[col].astype(str)\n",
        "            if col not in encoders:\n",
        "                encoders[col] = LabelEncoder().fit(df[col])\n",
        "            df[col] = encoders[col].transform(df[col])\n",
        "        else:\n",
        "            df[col] = SimpleImputer(strategy=\"mean\").fit_transform(df[[col]])\n",
        "    return df, encoders\n",
        "\n",
        "X, encoders = preprocess(X)\n",
        "X_test, _ = preprocess(X_test, encoders)\n",
        "\n",
        "# ✅ 기본 모델\n",
        "model_lgbm = LGBMClassifier(learning_rate=0.05, max_depth=6, num_leaves=31, random_state=42)\n",
        "model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "model_cat = CatBoostClassifier(verbose=0, random_state=42)\n",
        "\n",
        "# ✅ 메타 모델 (LGBMClassifier로 변경)\n",
        "meta_model = LGBMClassifier(learning_rate=0.05, max_depth=3, num_leaves=15, random_state=42)\n",
        "\n",
        "# ✅ 스태킹 모델 정의\n",
        "base_models = [\n",
        "    ('lgbm', model_lgbm),\n",
        "    ('xgb', model_xgb),\n",
        "    ('cat', model_cat)\n",
        "]\n",
        "\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=meta_model,\n",
        "    cv=5,\n",
        "    stack_method=\"predict_proba\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# ✅ Threshold 최적화\n",
        "oof_preds = cross_val_predict(stack_model, X, y, method=\"predict_proba\", cv=5)[:, 1]\n",
        "thresholds = np.arange(0.1, 0.9, 0.01)\n",
        "f1s = [f1_score(y, oof_preds > t) for t in thresholds]\n",
        "best_thresh = thresholds[np.argmax(f1s)]\n",
        "print(f\"Best Threshold: {best_thresh:.2f}, Best F1 Score: {max(f1s):.5f}\")\n",
        "\n",
        "# ✅ 최종 학습 및 예측\n",
        "stack_model.fit(X, y)\n",
        "test_preds = stack_model.predict_proba(X_test)[:, 1]\n",
        "submission[\"Cancer\"] = (test_preds > best_thresh).astype(int)\n",
        "submission.to_csv(\"submission_stacking_lgb_meta.csv\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "F-qD15DMqv1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔸 선택 시 다운로드 코드\n",
        "from google.colab import files\n",
        "files.download(\"submission_stacking_lgb_meta.csv\")"
      ],
      "metadata": {
        "id": "Z69aw153qv85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "✅ 1. LightGBM 단독 모델에 다른 모델 보조 적용 전략\n",
        "🔸 전략 A: Soft Voting Ensemble\n",
        "LightGBM + CatBoost + XGBoost 등을 soft voting으로 앙상블\n",
        "\n",
        "장점: 서로 다른 모델의 강점을 결합\n",
        "\n",
        "구현:\n",
        "\n",
        "python\n",
        "복사\n",
        "편집\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbm = LGBMClassifier(**best_params)\n",
        "xgb = XGBClassifier(eval_metric='logloss')\n",
        "cat = CatBoostClassifier(verbose=0)\n",
        "\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[(\"lgbm\", lgbm), (\"xgb\", xgb), (\"cat\", cat)],\n",
        "    voting=\"soft\"\n",
        ")\n",
        "🔸 전략 B: StackingClassifier\n",
        "Level-1 모델: LightGBM, CatBoost, XGBoost\n",
        "\n",
        "Meta 모델: Logistic Regression 또는 LGBM\n",
        "\n",
        "장점: 모델 간 의사결정 차이를 메타 모델이 보완\n",
        "\n",
        "구현 예시:\n",
        "\n",
        "python\n",
        "복사\n",
        "편집\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "base_models = [\n",
        "    ('lgbm', LGBMClassifier(**best_params)),\n",
        "    ('xgb', XGBClassifier(eval_metric='logloss')),\n",
        "    ('cat', CatBoostClassifier(verbose=0))\n",
        "]\n",
        "stack_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
        "✅ 2. LightGBM + SHAP 기반 변수 → 다른 모델 활용\n",
        "SHAP으로 파생된 상호작용 feature를 LightGBM에서 먼저 분석\n",
        "\n",
        "이 feature만 추출해서 XGBoost나 CatBoost에 적용\n",
        "\n",
        "LightGBM → Feature Engineering, XGB/Cat → 최종 분류기\n",
        "\n",
        "장점: 해석력 + 성능 조화\n",
        "\n",
        "✅ 3. LightGBM + Neural Network 하이브리드 (고급 전략)\n",
        "LightGBM의 출력(leaf index 또는 예측값)을 Neural Network의 feature로 사용\n",
        "\n",
        "또는 TabNet 같은 모델과 병렬적으로 조합\n",
        "\n",
        "복잡하지만 성능 상승 여지 있음\n",
        "\n",
        "🔍 추천 실험 순서\n",
        "LightGBM 단독 기준 성능 확보 → 완료됨 ✅\n",
        "\n",
        "Soft Voting (LGBM + XGB + CatBoost) → 빠른 성능 확인 가능\n",
        "\n",
        "StackingClassifier 적용 → 성능 개선 여지 있음\n",
        "\n",
        "Focal Loss + Sample Weight 조합 → 미세 튜닝\n",
        "\n",
        "SHAP 기반 변수만 추출 후 각 모델 실험\n",
        "\n",
        "딥러닝/TabNet 병합 (필요시)"
      ],
      "metadata": {
        "id": "hO8qIuAK-X1E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}